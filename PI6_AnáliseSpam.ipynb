{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cdfbc1d-9553-48ca-bd5f-9d18012d5c16",
   "metadata": {},
   "source": [
    "#### *Situação Problema* \n",
    "\n",
    "##### Uma operadora de telecomunicações está recebendo reclamações de clientes sobre mensagens de spam em seus celulares. Essas mensagens não só irritam os usuários, mas também podem levar a golpes financeiros. A empresa contratou sua equipe para desenvolver um modelo de classificação automática que identifique mensagens spam com alta precisão, evitando bloquear mensagens legítimas (especialmente alertas importantes, como notificações bancárias ou emergenciais).\n",
    "\n",
    "##### Objetivo: Criar um modelo de machine learning que classifique SMS como ham ou spam com base no conteúdo textual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c985a7-c151-4083-80c0-ae3790cd6033",
   "metadata": {},
   "source": [
    "##### 1. Carregamento e exploração inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9cddcd3-8fa8-4ff2-8dfa-40d830b83189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['label', 'message'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f63b14fb-1e51-44bc-b669-6d0729455502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   label           5572 non-null   object\n",
      " 1   message         5572 non-null   object\n",
      " 2   mensagem_limpa  5572 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 130.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5dbcd-dc37-4648-ac45-bfe373dc4d3b",
   "metadata": {},
   "source": [
    "\n",
    "##### Ham vs. Spam\n",
    "\n",
    "##### Ham = mensagens normais e úteis\n",
    "\n",
    "##### Spam = mensagens indesejadas, como propagandas, golpes ou notificações invasivas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5eed79c-a77d-4a4f-b273-29c25714a921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar quantas mensagens são ham e quantas são spam\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d6eabf0-93b3-4913-b7c0-3730ae8d5817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensagens HAM:\n",
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "Name: message, dtype: object \n",
      "\n",
      "Mensagens SPAM:\n",
      "2     Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "5     FreeMsg Hey there darling it's been 3 week's n...\n",
      "8     WINNER!! As a valued network customer you have...\n",
      "9     Had your mobile 11 months or more? U R entitle...\n",
      "11    SIX chances to win CASH! From 100 to 20,000 po...\n",
      "Name: message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verificar exemplos de mensagens de cada classe (5)\n",
    "\n",
    "# Exemplo mensagens 'ham' \n",
    "print(\"Mensagens HAM:\")\n",
    "print(df[df['label'] == 'ham']['message'].head(), \"\\n\")\n",
    "\n",
    "# Exemplo mensagens 'Spam'\n",
    "print(\"Mensagens SPAM:\")\n",
    "print(df[df['label'] == 'spam']['message'].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9f18c-70a7-44eb-96fe-83354febeffa",
   "metadata": {},
   "source": [
    "##### 2. Pré-processamento de texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "496fc3e5-434d-49fe-86b2-671c28de55bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>mensagem_limpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  Go until jurong point, crazy.. Available only ...   \n",
       "1                      Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3  U dun say so early hor... U c already then say...   \n",
       "4  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                      mensagem_limpa  \n",
       "0  go until jurong point crazy available only in ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry in a wkly comp to win fa cup final ...  \n",
       "3        u dun say so early hor u c already then say  \n",
       "4  nah i dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpar o texto: remover caracteres especiais, números e converter para minúsculas.\n",
    "\n",
    "import re # ferramentas para procurar e manipular textos com padrões.\n",
    "\n",
    "def limpar_texto(texto):\n",
    "    texto = texto.lower()  # converte para minúsculas\n",
    "    texto = re.sub(r'[^a-z\\s]', '', texto)  # remove números e caracteres especiais\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()  # remove espaços duplicados e espaços no início/fim\n",
    "    return texto\n",
    "\n",
    "# Aplicar a função de limpeza à coluna 'message'\n",
    "df['mensagem_limpa'] = df['message'].apply(limpar_texto)\n",
    "\n",
    "df[['message', 'mensagem_limpa']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac42838-ee2a-4ca4-9e9f-5f167a78e089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mensagem_limpa</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mensagem_limpa  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in a wkly comp to win fa cup final ...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [go, until, jurong, point, crazy, available, o...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, in, a, wkly, comp, to, win, fa, ...  \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4  [nah, i, dont, think, he, goes, to, usf, he, l...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Tokenizar as mensagens (dividir o texto em pedaços menores)\n",
    "\n",
    "df['tokens'] = df['mensagem_limpa'].apply(lambda x: x.split())\n",
    "\n",
    "# Exibir as colunas: original, limpa e tokens\n",
    "df[['mensagem_limpa', 'tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ee4884e-c7dc-4ff5-92ba-6737509d99fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\debor\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\debor\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\debor\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\debor\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\debor\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\debor\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "468432f7-c3d8-41ac-8735-fe2b632638b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\debor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mensagem_limpa</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mensagem_limpa  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in a wkly comp to win fa cup final ...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [go, until, jurong, point, crazy, available, o...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, in, a, wkly, comp, to, win, fa, ...  \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4  [nah, i, dont, think, he, goes, to, usf, he, l...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['tokens'] = df['mensagem_limpa'].apply(word_tokenize)\n",
    "df[['mensagem_limpa', 'tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b8791fa-3ea1-4622-a875-aac1fe7bd5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\debor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baixar as stopwords \n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')  # Baixa lista de stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63f04ab9-934a-4ec2-a1c2-a46c37f21236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Stopwords em inglês\n",
    "stopwords_en = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da445d6c-ccc4-43fb-8472-8abb9c1e0dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mensagem_limpa</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_sem_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mensagem_limpa  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in a wkly comp to win fa cup final ...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [go, until, jurong, point, crazy, available, o...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, in, a, wkly, comp, to, win, fa, ...   \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4  [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "\n",
       "                                tokens_sem_stopwords  \n",
       "0  [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, wkly, comp, win, fa, cup, final,...  \n",
       "3      [u, dun, say, early, hor, u, c, already, say]  \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Função para filtrar as stopwords de cada lista de tokens\n",
    "def remover_stopwords(tokens):\n",
    "    return [palavra for palavra in tokens if palavra not in stopwords_en]\n",
    "\n",
    "# Aplicar a função\n",
    "df['tokens_sem_stopwords'] = df['tokens'].apply(remover_stopwords)\n",
    "\n",
    "# Visualizar o resultado\n",
    "df[['mensagem_limpa', 'tokens', 'tokens_sem_stopwords']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e2b9d-5824-4bb3-87a1-bdfc0aad4c8b",
   "metadata": {},
   "source": [
    "##### 3. Vetorização dos Dados\n",
    "\n",
    "##### Converter texto em features numéricas usando TF-IDF ou Bag of Words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cded3c-78f7-4338-a2f2-8d1bf9b5f2ea",
   "metadata": {},
   "source": [
    "##### Bag of Words é mais simples, mas pode dar pesos iguais a todas as palavras, mesmo aquelas que não são tão informativas.\n",
    "\n",
    "##### TF-IDF geralmente funciona melhor em tarefas de classificação de texto, pois ele destaca as palavras mais relevantes para distinguir entre as classes.\n",
    "\n",
    "* #####  Considerando que nosso objetivo é classificar mensagens como spam ou ham, o TF-IDF tende a ser uma escolha mais eficaz.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "176d3da8-9ef4-4342-a83f-a85af3c0d5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato da matriz TF-IDF: (5572, 8476)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Inicializar o vetorizador TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ajustar o vetorizador aos tokens (para criar o vocabulário)\n",
    "tfidf_vectorizer.fit(df['tokens_sem_stopwords'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Transformar os tokens em vetores TF-IDF\n",
    "tfidf_vectors = tfidf_vectorizer.transform(df['tokens_sem_stopwords'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "print(\"Formato da matriz TF-IDF:\", tfidf_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b90703-9e87-41c1-aa5f-8a86dcca66cf",
   "metadata": {},
   "source": [
    "##### 4. Divisão dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f6e4686-c43f-47b6-8d55-a8d27816bb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição original no treino:\n",
      "label\n",
      "ham     3377\n",
      "spam     523\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuição após SMOTE:\n",
      "label\n",
      "spam    3377\n",
      "ham     3377\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separar o dataset em conjuntos de treino (70%) e teste (30%) \n",
    "\n",
    "# Features \n",
    "X = tfidf_vectors\n",
    "\n",
    "# Rótulos\n",
    "y = df['label']\n",
    "\n",
    "# Divisão em treino (70%) e teste (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Visualizar distribuição original das classes no treino\n",
    "print(\"Distribuição original no treino:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# Aplicando SMOTE para balancear os dados no conjunto de treino\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Visualizar distribuição após o balanceamento\n",
    "print(\"\\nDistribuição após SMOTE:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
